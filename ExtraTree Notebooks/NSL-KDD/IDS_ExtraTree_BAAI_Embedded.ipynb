{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1hJMVVwqLh_0YNAPLxJ2ugZoonXALQgrj","timestamp":1760248270468},{"file_id":"11pQYQn8-I0KHiTFjof3wIrD3wRCj6ZR8","timestamp":1759424512819},{"file_id":"10lLNRo_hgp4SSK7d95cX4b0uaLQ3INip","timestamp":1759407795167},{"file_id":"118HYcJoOR6ViRHvhOCH64XhMX6xSiMe_","timestamp":1759215435771}],"machine_shape":"hm","gpuType":"A100","authorship_tag":"ABX9TyPbzRMeDoQg7KTPis3Pc8Rd"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["# ─────────────────────────────────────────────────────────────\n","# 0. Imports\n","# ─────────────────────────────────────────────────────────────\n","import os\n","import numpy as np\n","import pandas as pd\n","from tqdm import tqdm\n","from sklearn.metrics import (\n","    classification_report, confusion_matrix,\n","    accuracy_score, precision_score, recall_score, f1_score\n",")\n","from sklearn.preprocessing import LabelEncoder, normalize\n","from sentence_transformers import SentenceTransformer\n","from sklearn.ensemble import ExtraTreesClassifier\n","import torch\n","import time\n","from google.colab import drive\n","\n","# ─────────────────────────────────────────────────────────────\n","# 1. Mount Google Drive\n","# ─────────────────────────────────────────────────────────────\n","drive.mount('/content/drive')\n","\n","# ─────────────────────────────────────────────────────────────\n","# 2. Load NSL-KDD train/test\n","# ─────────────────────────────────────────────────────────────\n","train_path = \"/content/drive/MyDrive/Research Project/KDDTrain+.txt\"\n","test_path  = \"/content/drive/MyDrive/Research Project/KDDTest+.txt\"\n","\n","columns = [\n","    \"duration\",\"protocol_type\",\"service\",\"flag\",\"src_bytes\",\"dst_bytes\",\n","    \"land\",\"wrong_fragment\",\"urgent\",\"hot\",\"num_failed_logins\",\"logged_in\",\n","    \"num_compromised\",\"root_shell\",\"su_attempted\",\"num_root\",\"num_file_creations\",\n","    \"num_shells\",\"num_access_files\",\"num_outbound_cmds\",\"is_host_login\",\n","    \"is_guest_login\",\"count\",\"srv_count\",\"serror_rate\",\"srv_serror_rate\",\n","    \"rerror_rate\",\"srv_rerror_rate\",\"same_srv_rate\",\"diff_srv_rate\",\n","    \"srv_diff_host_rate\",\"dst_host_count\",\"dst_host_srv_count\",\n","    \"dst_host_same_srv_rate\",\"dst_host_diff_srv_rate\",\"dst_host_same_src_port_rate\",\n","    \"dst_host_srv_diff_host_rate\",\"dst_host_serror_rate\",\"dst_host_srv_serror_rate\",\n","    \"dst_host_rerror_rate\",\"dst_host_srv_rerror_rate\",\n","    \"attack_type\",\"difficulty\"\n","]\n","\n","train_df = pd.read_csv(train_path, header=None, names=columns)\n","test_df  = pd.read_csv(test_path,  header=None, names=columns)\n","\n","print(f\"Train shape: {train_df.shape}, Test shape: {test_df.shape}\")\n","\n","# ─────────────────────────────────────────────────────────────\n","# 3. Binary labels\n","# ─────────────────────────────────────────────────────────────\n","train_df[\"label\"] = (train_df[\"attack_type\"] != \"normal\").astype(int)\n","test_df[\"label\"]  = (test_df[\"attack_type\"]  != \"normal\").astype(int)\n","\n","# ─────────────────────────────────────────────────────────────\n","# 4. Encode categorical features safely\n","# ─────────────────────────────────────────────────────────────\n","categorical_cols = [\"protocol_type\", \"service\", \"flag\"]\n","for col in categorical_cols:\n","    le = LabelEncoder()\n","    combined = pd.concat([train_df[col].astype(str), test_df[col].astype(str)], axis=0)\n","    le.fit(combined)\n","    train_df[col] = le.transform(train_df[col].astype(str))\n","    test_df[col]  = le.transform(test_df[col].astype(str))\n","\n","# ─────────────────────────────────────────────────────────────\n","# 5. Select numeric columns\n","# ─────────────────────────────────────────────────────────────\n","drop_cols = [\"attack_type\", \"difficulty\", \"label\"]\n","num_cols = [c for c in train_df.columns if c not in drop_cols and pd.api.types.is_numeric_dtype(train_df[c])]\n","X_train_num = train_df[num_cols].values\n","X_test_num  = test_df[num_cols].values\n","y_train = train_df[\"label\"].values\n","y_test  = test_df[\"label\"].values\n","print(f\"Using {len(num_cols)} numeric features\")\n","\n","# ─────────────────────────────────────────────────────────────\n","# 6. Flow-style summaries for embedding\n","# ─────────────────────────────────────────────────────────────\n","def make_summary(row):\n","    g = row.get\n","    proto  = g(\"protocol_type\",\"NA\")\n","    serv   = g(\"service\",\"NA\")\n","    flag   = g(\"flag\",\"NA\")\n","    src_b  = g(\"src_bytes\",0)\n","    dst_b  = g(\"dst_bytes\",0)\n","    dur    = g(\"duration\",0.0)\n","    serror = g(\"serror_rate\",0.0)\n","    rerror = g(\"rerror_rate\",0.0)\n","    count  = g(\"count\",0)\n","    srv_ct = g(\"srv_count\",0)\n","    return (f\"Connection: proto={proto}, service={serv}, flag={flag}, \"\n","            f\"duration={dur:.2f}s, src_bytes={src_b}, dst_bytes={dst_b}, \"\n","            f\"serror_rate={serror:.2f}, rerror_rate={rerror:.2f}, \"\n","            f\"count={count}, srv_count={srv_ct}\")\n","\n","train_summaries = train_df.apply(make_summary, axis=1).tolist()\n","test_summaries  = test_df.apply(make_summary, axis=1).tolist()\n","print(\"Example summary:\", train_summaries[0][:120], \"...\")\n","\n","# ─────────────────────────────────────────────────────────────\n","# 7. Load BGE model\n","# ─────────────────────────────────────────────────────────────\n","print(\"\\nLoading BGE model...\")\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","bge_model = SentenceTransformer(\"BAAI/bge-small-en-v1.5\", device=device)\n","\n","# ─────────────────────────────────────────────────────────────\n","# 8. Compute embeddings\n","# ─────────────────────────────────────────────────────────────\n","def compute_bge_embeddings(texts, batch_size=32):\n","    all_embs = []\n","    for i in tqdm(range(0, len(texts), batch_size), desc=\"Embedding with BGE\"):\n","        batch = texts[i:i+batch_size]\n","        emb = bge_model.encode(batch, convert_to_numpy=True, normalize_embeddings=True, show_progress_bar=False)\n","        all_embs.append(emb)\n","    return np.vstack(all_embs)\n","\n","t0 = time.perf_counter()\n","train_emb = compute_bge_embeddings(train_summaries)\n","t1 = time.perf_counter()\n","print(f\"Train embedding time/sample: {(t1 - t0)/len(train_summaries)*1000:.2f} ms\")\n","\n","t0 = time.perf_counter()\n","test_emb = compute_bge_embeddings(test_summaries)\n","t1 = time.perf_counter()\n","print(f\"Test embedding time/sample: {(t1 - t0)/len(test_summaries)*1000:.2f} ms\")\n","\n","# ─────────────────────────────────────────────────────────────\n","# 9. Combine numeric + BGE embeddings\n","# ─────────────────────────────────────────────────────────────\n","X_train = np.hstack([X_train_num, train_emb])\n","X_test  = np.hstack([X_test_num,  test_emb])\n","print(\"Final training shape:\", X_train.shape)\n","\n","# ─────────────────────────────────────────────────────────────\n","# 10. Train & Evaluate Extra Trees\n","# ─────────────────────────────────────────────────────────────\n","clf = ExtraTreesClassifier(\n","    n_estimators=300,\n","    max_depth=None,\n","    min_samples_leaf=5,\n","    class_weight=\"balanced\",\n","    n_jobs=-1,\n","    random_state=42\n",")\n","\n","print(\"\\nTraining Extra Trees model...\")\n","t0 = time.perf_counter()\n","clf.fit(X_train, y_train)\n","t1 = time.perf_counter()\n","print(f\"Training time: {(t1 - t0):.2f}s\")\n","\n","# ─────────────────────────────────────────────────────────────\n","# 11. Evaluation\n","# ─────────────────────────────────────────────────────────────\n","y_pred = clf.predict(X_test)\n","print(\"\\nPerformance Report (BGE + ExtraTrees):\")\n","print(f\"Accuracy : {accuracy_score(y_test, y_pred):.3f}\")\n","print(f\"Precision: {precision_score(y_test, y_pred):.3f}\")\n","print(f\"Recall   : {recall_score(y_test, y_pred):.3f}\")\n","print(f\"F1 Score : {f1_score(y_test, y_pred):.3f}\")\n","print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred, target_names=[\"normal\",\"attack\"]))\n","print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VpVIp2J-2ftV","executionInfo":{"status":"ok","timestamp":1760248586603,"user_tz":-630,"elapsed":121195,"user":{"displayName":"Tuhin Anand","userId":"00460084127537747763"}},"outputId":"873dcd99-15d8-47b7-9cd2-9b0eb3609350"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Train shape: (125973, 43), Test shape: (22544, 43)\n","Using 41 numeric features\n","Example summary: Connection: proto=1, service=20, flag=9, duration=0.00s, src_bytes=491, dst_bytes=0, serror_rate=0.00, rerror_rate=0.00, ...\n","\n","Loading BGE model...\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n","Embedding with BGE: 100%|██████████| 3937/3937 [01:05<00:00, 60.45it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train embedding time/sample: 0.52 ms\n"]},{"output_type":"stream","name":"stderr","text":["Embedding with BGE: 100%|██████████| 705/705 [00:11<00:00, 60.77it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Test embedding time/sample: 0.52 ms\n","Final training shape: (125973, 425)\n","\n","Training Extra Trees model...\n","Training time: 25.56s\n","\n","Performance Report (BGE + ExtraTrees on NSL-KDD):\n","Accuracy : 0.815\n","Precision: 0.969\n","Recall   : 0.697\n","F1 Score : 0.811\n","\n","Classification Report:\n","               precision    recall  f1-score   support\n","\n","      normal       0.71      0.97      0.82      9711\n","      attack       0.97      0.70      0.81     12833\n","\n","    accuracy                           0.81     22544\n","   macro avg       0.84      0.83      0.81     22544\n","weighted avg       0.86      0.81      0.81     22544\n","\n","Confusion Matrix:\n"," [[9421  290]\n"," [3889 8944]]\n"]}]},{"cell_type":"code","source":["from sklearn.metrics import roc_auc_score\n","\n","def evaluate_model(clf, X_test, y_test):\n","    import time\n","    start = time.perf_counter()\n","    y_pred = clf.predict(X_test)\n","    end = time.perf_counter()\n","    cls_latency = (end - start) / len(y_test) * 1000  # ms per sample\n","\n","    y_proba = clf.predict_proba(X_test)[:,1] if hasattr(clf, \"predict_proba\") else None\n","\n","    # Confusion matrix + FPR\n","    cm = confusion_matrix(y_test, y_pred, labels=[0,1])\n","    tn, fp, fn, tp = cm.ravel()\n","    fpr = fp / (fp + tn) if (fp + tn) > 0 else 0.0\n","\n","    results = {\n","        \"Accuracy\": accuracy_score(y_test, y_pred),\n","        \"Precision\": precision_score(y_test, y_pred),\n","        \"Recall\": recall_score(y_test, y_pred),\n","        \"F1\": f1_score(y_test, y_pred),\n","        \"ROC-AUC\": roc_auc_score(y_test, y_proba) if y_proba is not None else None,\n","        \"FPR\": fpr,\n","        \"ConfusionMatrix\": cm.tolist(),\n","        \"Latency_cls_ms\": cls_latency\n","    }\n","    return results\n"],"metadata":{"id":"2Lmh-VvyPlMb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import numpy as np\n","import os\n","\n","def save_confusion_matrix(cm, run_name, out_dir=\"/content/drive/MyDrive/Results/NSB/ExtraTreesClassifier\"):\n","    os.makedirs(out_dir, exist_ok=True)\n","    # Save CSV\n","    np.savetxt(os.path.join(out_dir, f\"{run_name}_cm.csv\"), cm, fmt=\"%d\", delimiter=\",\")\n","\n","    # Save image\n","    fig, ax = plt.subplots(figsize=(4,4))\n","    im = ax.imshow(cm, cmap=\"Blues\")\n","    ax.set_title(f\"Confusion Matrix - {run_name}\")\n","    ax.set_xlabel(\"Predicted\")\n","    ax.set_ylabel(\"True\")\n","    ax.set_xticks([0,1]); ax.set_xticklabels([\"Normal\",\"Attack\"])\n","    ax.set_yticks([0,1]); ax.set_yticklabels([\"Normal\",\"Attack\"])\n","\n","    for i in range(cm.shape[0]):\n","        for j in range(cm.shape[1]):\n","            ax.text(j, i, cm[i,j], ha=\"center\", va=\"center\", color=\"red\")\n","\n","    fig.colorbar(im, ax=ax)\n","    fig.tight_layout()\n","    fig.savefig(os.path.join(out_dir, f\"{run_name}_cm.png\"))\n","    plt.close(fig)\n"],"metadata":{"id":"jo2i4i3cPloY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import json\n","\n","results = evaluate_model(clf, X_test, y_test)\n","\n","cm = np.array(results[\"ConfusionMatrix\"])\n","save_confusion_matrix(cm, run_name=\"BAAI_DT\")\n","\n","with open(\"/content/drive/MyDrive/Results/NSB/ExtraTreesClassifier/BAAI_Results.txt\", \"w\") as f:\n","    json.dump(results, f, indent=2)\n"],"metadata":{"id":"9AHHIFdZPrNF"},"execution_count":null,"outputs":[]}]}