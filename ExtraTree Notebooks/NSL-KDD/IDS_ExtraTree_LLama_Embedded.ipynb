{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hujztC_1Li0R"
   },
   "outputs": [],
   "source": [
    "# ─────────────────────────────────────────────────────────────\n",
    "# 0. Imports\n",
    "# ─────────────────────────────────────────────────────────────\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix,\n",
    "    accuracy_score, precision_score, recall_score, f1_score\n",
    ")\n",
    "from sklearn.preprocessing import LabelEncoder, normalize\n",
    "from sklearn.decomposition import PCA\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import LlamaTokenizer, LlamaModel\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "import torch\n",
    "import time\n",
    "from google.colab import drive\n",
    "from huggingface_hub import login\n",
    "import json\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────\n",
    "# 1. Mount Google Drive\n",
    "# ─────────────────────────────────────────────────────────────\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────\n",
    "# 2. Load NSL-KDD train/test\n",
    "# ─────────────────────────────────────────────────────────────\n",
    "train_path = \"/content/drive/MyDrive/Research Project/KDDTrain+.txt\"\n",
    "test_path  = \"/content/drive/MyDrive/Research Project/KDDTest+.txt\"\n",
    "\n",
    "columns = [\n",
    "    \"duration\",\"protocol_type\",\"service\",\"flag\",\"src_bytes\",\"dst_bytes\",\n",
    "    \"land\",\"wrong_fragment\",\"urgent\",\"hot\",\"num_failed_logins\",\"logged_in\",\n",
    "    \"num_compromised\",\"root_shell\",\"su_attempted\",\"num_root\",\"num_file_creations\",\n",
    "    \"num_shells\",\"num_access_files\",\"num_outbound_cmds\",\"is_host_login\",\n",
    "    \"is_guest_login\",\"count\",\"srv_count\",\"serror_rate\",\"srv_serror_rate\",\n",
    "    \"rerror_rate\",\"srv_rerror_rate\",\"same_srv_rate\",\"diff_srv_rate\",\n",
    "    \"srv_diff_host_rate\",\"dst_host_count\",\"dst_host_srv_count\",\n",
    "    \"dst_host_same_srv_rate\",\"dst_host_diff_srv_rate\",\"dst_host_same_src_port_rate\",\n",
    "    \"dst_host_srv_diff_host_rate\",\"dst_host_serror_rate\",\"dst_host_srv_serror_rate\",\n",
    "    \"dst_host_rerror_rate\",\"dst_host_srv_rerror_rate\",\n",
    "    \"attack_type\",\"difficulty\"\n",
    "]\n",
    "\n",
    "train_df = pd.read_csv(train_path, header=None, names=columns)\n",
    "test_df  = pd.read_csv(test_path,  header=None, names=columns)\n",
    "\n",
    "print(f\"Train shape: {train_df.shape}, Test shape: {test_df.shape}\")\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────\n",
    "# 3. Binary labels\n",
    "# ─────────────────────────────────────────────────────────────\n",
    "train_df[\"label\"] = (train_df[\"attack_type\"] != \"normal\").astype(int)\n",
    "test_df[\"label\"]  = (test_df[\"attack_type\"]  != \"normal\").astype(int)\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────\n",
    "# 4. Encode categorical features\n",
    "# ─────────────────────────────────────────────────────────────\n",
    "categorical_cols = [\"protocol_type\", \"service\", \"flag\"]\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    combined = pd.concat([train_df[col].astype(str), test_df[col].astype(str)], axis=0)\n",
    "    le.fit(combined)\n",
    "    train_df[col] = le.transform(train_df[col].astype(str))\n",
    "    test_df[col]  = le.transform(test_df[col].astype(str))\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────\n",
    "# 5. Select numeric columns\n",
    "# ─────────────────────────────────────────────────────────────\n",
    "drop_cols = [\"attack_type\", \"difficulty\", \"label\"]\n",
    "num_cols = [c for c in train_df.columns if c not in drop_cols and pd.api.types.is_numeric_dtype(train_df[c])]\n",
    "\n",
    "X_train_num = train_df[num_cols].values\n",
    "X_test_num  = test_df[num_cols].values\n",
    "y_train = train_df[\"label\"].values\n",
    "y_test  = test_df[\"label\"].values\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────\n",
    "# 6. Flow summaries for LLaMA\n",
    "# ─────────────────────────────────────────────────────────────\n",
    "def make_summary(row):\n",
    "    g = row.get\n",
    "    proto  = g(\"protocol_type\",\"NA\")\n",
    "    serv   = g(\"service\",\"NA\")\n",
    "    flag   = g(\"flag\",\"NA\")\n",
    "    src_b  = g(\"src_bytes\",0)\n",
    "    dst_b  = g(\"dst_bytes\",0)\n",
    "    dur    = g(\"duration\",0.0)\n",
    "    serror = g(\"serror_rate\",0.0)\n",
    "    rerror = g(\"rerror_rate\",0.0)\n",
    "    count  = g(\"count\",0)\n",
    "    srv_ct = g(\"srv_count\",0)\n",
    "    return (f\"Connection: proto={proto}, service={serv}, flag={flag}, \"\n",
    "            f\"duration={dur:.2f}s, src_bytes={src_b}, dst_bytes={dst_b}, \"\n",
    "            f\"serror_rate={serror:.2f}, rerror_rate={rerror:.2f}, \"\n",
    "            f\"count={count}, srv_count={srv_ct}\")\n",
    "\n",
    "train_summaries = train_df.apply(make_summary, axis=1).tolist()\n",
    "test_summaries  = test_df.apply(make_summary, axis=1).tolist()\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────\n",
    "# 7. Load LLaMA-2 model\n",
    "# ─────────────────────────────────────────────────────────────\n",
    "login(token=\"your token hugging face\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "tokenizer = LlamaTokenizer.from_pretrained(\n",
    "    \"meta-llama/Llama-2-7b-hf\",\n",
    "    use_auth_token=True\n",
    ")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "model = LlamaModel.from_pretrained(\n",
    "    \"meta-llama/Llama-2-7b-hf\",\n",
    "    use_auth_token=True,\n",
    "    torch_dtype=torch.float16,\n",
    "    low_cpu_mem_usage=True,\n",
    "    output_hidden_states=True\n",
    ").to(device)\n",
    "model.eval()\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────\n",
    "# 8. Embedding function\n",
    "# ─────────────────────────────────────────────────────────────\n",
    "class SummaryDataset(Dataset):\n",
    "    def __init__(self, summaries): self.summaries = summaries\n",
    "    def __len__(self): return len(self.summaries)\n",
    "    def __getitem__(self, idx): return self.summaries[idx]\n",
    "\n",
    "def collate_fn(batch):\n",
    "    return tokenizer(batch, return_tensors=\"pt\", padding=True, truncation=True, max_length=128)\n",
    "\n",
    "def compute_embeddings(summaries, batch_size=32):\n",
    "    ds = SummaryDataset(summaries)\n",
    "    loader = DataLoader(ds, batch_size=batch_size, collate_fn=collate_fn)\n",
    "    all_embs = []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(loader, desc=\"Embedding with LLaMA-2\"):\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            outputs = model(**batch)\n",
    "            last_hidden = outputs.hidden_states[-1]\n",
    "            pooled = last_hidden.mean(dim=1).cpu().numpy()\n",
    "            all_embs.append(pooled)\n",
    "    return np.vstack(all_embs)\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────\n",
    "# 9. Compute embeddings\n",
    "# ─────────────────────────────────────────────────────────────\n",
    "t0 = time.perf_counter()\n",
    "train_emb = compute_embeddings(train_summaries)\n",
    "t1 = time.perf_counter()\n",
    "print(f\"Train embedding time/sample: {(t1 - t0)/len(train_summaries)*1000:.2f} ms\")\n",
    "\n",
    "t0 = time.perf_counter()\n",
    "test_emb = compute_embeddings(test_summaries)\n",
    "t1 = time.perf_counter()\n",
    "print(f\"Test embedding time/sample: {(t1 - t0)/len(test_summaries)*1000:.2f} ms\")\n",
    "\n",
    "train_emb = normalize(train_emb, axis=1)\n",
    "test_emb  = normalize(test_emb, axis=1)\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────\n",
    "# 10. Combine numeric + LLaMA embeddings\n",
    "# ─────────────────────────────────────────────────────────────\n",
    "X_train = np.hstack([X_train_num, train_emb])\n",
    "X_test  = np.hstack([X_test_num,  test_emb])\n",
    "print(\"Final training shape:\", X_train.shape)\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────\n",
    "# 11. Train & Evaluate Extra Trees\n",
    "# ─────────────────────────────────────────────────────────────\n",
    "clf = ExtraTreesClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=None,\n",
    "    min_samples_leaf=5,\n",
    "    class_weight=\"balanced\",\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"\\nTraining ExtraTreesClassifier model...\")\n",
    "t0 = time.perf_counter()\n",
    "clf.fit(X_train, y_train)\n",
    "t1 = time.perf_counter()\n",
    "print(f\"Training time: {(t1 - t0):.2f}s\")\n",
    "\n",
    "# ─────────────────────────────────────────────────────────────\n",
    "# 12. Evaluation\n",
    "# ─────────────────────────────────────────────────────────────\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(\"\\nPerformance Report (LLaMA-2 + ExtraTrees):\")\n",
    "print(f\"Accuracy : {accuracy_score(y_test, y_pred):.3f}\")\n",
    "print(f\"Precision: {precision_score(y_test, y_pred):.3f}\")\n",
    "print(f\"Recall   : {recall_score(y_test, y_pred):.3f}\")\n",
    "print(f\"F1 Score : {f1_score(y_test, y_pred):.3f}\")\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred, target_names=[\"normal\",\"attack\"]))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OP9RUwZvMJTn"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def evaluate_model(clf, X_test, y_test):\n",
    "    import time\n",
    "    start = time.perf_counter()\n",
    "    y_pred = clf.predict(X_test)\n",
    "    end = time.perf_counter()\n",
    "    cls_latency = (end - start) / len(y_test) * 1000\n",
    "    y_proba = clf.predict_proba(X_test)[:,1] if hasattr(clf, \"predict_proba\") else None\n",
    "\n",
    "    # Confusion matrix + FPR\n",
    "    cm = confusion_matrix(y_test, y_pred, labels=[0,1])\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    fpr = fp / (fp + tn) if (fp + tn) > 0 else 0.0\n",
    "\n",
    "    results = {\n",
    "        \"Accuracy\": accuracy_score(y_test, y_pred),\n",
    "        \"Precision\": precision_score(y_test, y_pred),\n",
    "        \"Recall\": recall_score(y_test, y_pred),\n",
    "        \"F1\": f1_score(y_test, y_pred),\n",
    "        \"ROC-AUC\": roc_auc_score(y_test, y_proba) if y_proba is not None else None,\n",
    "        \"FPR\": fpr,\n",
    "        \"ConfusionMatrix\": cm.tolist(),\n",
    "        \"Latency_cls_ms\": cls_latency\n",
    "    }\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AN4woa59MKFN"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def save_confusion_matrix(cm, run_name, out_dir=\"/content/drive/MyDrive/Results/NSB/ExtraTreesClassifier\"):\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "    np.savetxt(os.path.join(out_dir, f\"{run_name}_cm.csv\"), cm, fmt=\"%d\", delimiter=\",\")\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(4,4))\n",
    "    im = ax.imshow(cm, cmap=\"Blues\")\n",
    "    ax.set_title(f\"Confusion Matrix - {run_name}\")\n",
    "    ax.set_xlabel(\"Predicted\")\n",
    "    ax.set_ylabel(\"True\")\n",
    "    ax.set_xticks([0,1]); ax.set_xticklabels([\"Normal\",\"Attack\"])\n",
    "    ax.set_yticks([0,1]); ax.set_yticklabels([\"Normal\",\"Attack\"])\n",
    "\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, cm[i,j], ha=\"center\", va=\"center\", color=\"red\")\n",
    "\n",
    "    fig.colorbar(im, ax=ax)\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(os.path.join(out_dir, f\"{run_name}_cm.png\"))\n",
    "    plt.close(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LDSCiSRkMQc_"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "results = evaluate_model(clf, X_test, y_test)\n",
    "\n",
    "cm = np.array(results[\"ConfusionMatrix\"])\n",
    "save_confusion_matrix(cm, run_name=\"LLama_DT\")\n",
    "\n",
    "with open(\"/content/drive/MyDrive/Results/NSB/ExtraTreesClassifier/LLama_Results.txt\", \"w\") as f:\n",
    "    json.dump(results, f, indent=2)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "machine_shape": "hm",
   "provenance": [
    {
     "file_id": "1C_rsqdeX8MZakp9Rca7vIgNpUWwj_DTU",
     "timestamp": 1760250757250
    },
    {
     "file_id": "1fWdMIQc4q0yXmWc1fxwiOUhdTUrqA0Kn",
     "timestamp": 1759424434222
    },
    {
     "file_id": "1nYUhqwWiKxX2iUQoo_Zakinv3jV7VjBO",
     "timestamp": 1759420687572
    },
    {
     "file_id": "1L3xiCZK4Xv9oM42lAAeflY-ABJFvIfmd",
     "timestamp": 1759215411430
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
