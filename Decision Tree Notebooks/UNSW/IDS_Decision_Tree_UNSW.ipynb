{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1c8PchP4ul7hgWobO05DjR-DNs0dh4XoQ","timestamp":1760269505276},{"file_id":"1l55ngbZW9jeKi68ThrgdZQdYZiavGH-O","timestamp":1759423256038},{"file_id":"1MDv7zGtQn1eC6EB2dguCNdrzpZudBoT4","timestamp":1759285160399},{"file_id":"1BSnBIoBP7QZNkA3HUQv1tS9yPzr1vni_","timestamp":1759214661154}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["# ─────────────────────────────────────────────────────────────\n","# 0. Imports\n","# ─────────────────────────────────────────────────────────────\n","import numpy as np\n","import pandas as pd\n","from sklearn.preprocessing import LabelEncoder, StandardScaler\n","from sklearn.tree import DecisionTreeClassifier\n","from sklearn.metrics import (\n","    classification_report, confusion_matrix,\n","    accuracy_score, precision_score, recall_score, f1_score\n",")\n","from google.colab import drive\n","from tqdm import tqdm\n","\n","# ─────────────────────────────────────────────────────────────\n","# 1. Mount Google Drive\n","# ─────────────────────────────────────────────────────────────\n","drive.mount('/content/drive')\n","\n","# ─────────────────────────────────────────────────────────────\n","# 2. Load UNSW-NB15 train/test\n","# ─────────────────────────────────────────────────────────────\n","train_path = \"/content/drive/MyDrive/Research Project/UNSW_NB15_training-set.csv\"\n","test_path  = \"/content/drive/MyDrive/Research Project/UNSW_NB15_testing-set.csv\"\n","\n","train_df = pd.read_csv(train_path)\n","test_df  = pd.read_csv(test_path)\n","\n","print(f\"Train shape: {train_df.shape}, Test shape: {test_df.shape}\")\n","print(\"Columns:\", list(train_df.columns)[:10], \"...\")\n","\n","# ─────────────────────────────────────────────────────────────\n","# 3. Label conversion\n","# ─────────────────────────────────────────────────────────────\n","if \"label\" not in train_df.columns:\n","    train_df[\"label\"] = (train_df[\"attack_cat\"].astype(str).str.lower() != \"normal\").astype(int)\n","    test_df[\"label\"]  = (test_df[\"attack_cat\"].astype(str).str.lower() != \"normal\").astype(int)\n","else:\n","    train_df[\"label\"] = (train_df[\"label\"] != 0).astype(int)\n","    test_df[\"label\"]  = (test_df[\"label\"]  != 0).astype(int)\n","\n","# ─────────────────────────────────────────────────────────────\n","# 4. Basic feature engineering\n","# ─────────────────────────────────────────────────────────────\n","for df in [train_df, test_df]:\n","    if \"sbytes\" in df.columns and \"dbytes\" in df.columns:\n","        df[\"bytes_ratio\"] = df[\"sbytes\"] / (df[\"dbytes\"] + 1)\n","        df[\"log_sbytes\"] = np.log1p(df[\"sbytes\"])\n","        df[\"log_dbytes\"] = np.log1p(df[\"dbytes\"])\n","    if \"dur\" in df.columns:\n","        df[\"log_dur\"] = np.log1p(df[\"dur\"])\n","    if \"spkts\" in df.columns and \"dpkts\" in df.columns:\n","        df[\"pkt_ratio\"] = df[\"spkts\"] / (df[\"dpkts\"] + 1)\n","\n","# ─────────────────────────────────────────────────────────────\n","# 5. Encode categorical features safely\n","# ─────────────────────────────────────────────────────────────\n","categorical_cols = [c for c in [\"proto\", \"service\", \"state\"] if c in train_df.columns]\n","for col in categorical_cols:\n","    le = LabelEncoder()\n","    combined = pd.concat([train_df[col].astype(str), test_df[col].astype(str)], axis=0)\n","    le.fit(combined)\n","    train_df[col] = le.transform(train_df[col].astype(str))\n","    test_df[col]  = le.transform(test_df[col].astype(str))\n","\n","# ─────────────────────────────────────────────────────────────\n","# 6. Select numeric columns\n","# ─────────────────────────────────────────────────────────────\n","drop_cols = [\"srcip\", \"dstip\", \"attack_cat\", \"label\"]\n","num_cols = [c for c in train_df.columns if c not in drop_cols and pd.api.types.is_numeric_dtype(train_df[c])]\n","print(f\"Using {len(num_cols)} numeric features\")\n","\n","X_train = train_df[num_cols].values\n","X_test  = test_df[num_cols].values\n","y_train = train_df[\"label\"].values\n","y_test  = test_df[\"label\"].values\n","\n","# ─────────────────────────────────────────────────────────────\n","# 7. Normalize features\n","# ─────────────────────────────────────────────────────────────\n","scaler = StandardScaler()\n","X_train = scaler.fit_transform(X_train)\n","X_test  = scaler.transform(X_test)\n","\n","# ─────────────────────────────────────────────────────────────\n","# 8. Train ExtraTrees baseline\n","# ─────────────────────────────────────────────────────────────\n","print(\"\\nTraining Decision Tree baseline...\")\n","clf = DecisionTreeClassifier(\n","    criterion=\"entropy\",\n","    max_depth=10,\n","    min_samples_leaf=5,\n","    random_state=42\n",")\n","clf.fit(X_train, y_train)\n","\n","# ─────────────────────────────────────────────────────────────\n","# 9. Evaluate\n","# ─────────────────────────────────────────────────────────────\n","y_pred = clf.predict(X_test)\n","\n","print(\"\\nBaseline Decision Performance:\")\n","print(f\"Accuracy : {accuracy_score(y_test, y_pred):.3f}\")\n","print(f\"Precision: {precision_score(y_test, y_pred):.3f}\")\n","print(f\"Recall   : {recall_score(y_test, y_pred):.3f}\")\n","print(f\"F1 Score : {f1_score(y_test, y_pred):.3f}\")\n","print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred, target_names=[\"normal\", \"attack\"]))\n","print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RjkYKpY1Yvky","executionInfo":{"status":"ok","timestamp":1760269742845,"user_tz":-630,"elapsed":7570,"user":{"displayName":"Tuhin Anand","userId":"00460084127537747763"}},"outputId":"0f58dc01-581a-44f9-9f2c-188d74e3b5df"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Train shape: (175341, 45), Test shape: (82332, 45)\n","Columns: ['id', 'dur', 'proto', 'service', 'state', 'spkts', 'dpkts', 'sbytes', 'dbytes', 'rate'] ...\n","Using 48 numeric features\n","\n","Training Decision Tree baseline...\n","\n","Baseline Decision Performance:\n","Accuracy : 0.504\n","Precision: 0.572\n","Recall   : 0.395\n","F1 Score : 0.468\n","\n","Classification Report:\n","               precision    recall  f1-score   support\n","\n","      normal       0.46      0.64      0.54     37000\n","      attack       0.57      0.40      0.47     45332\n","\n","    accuracy                           0.50     82332\n","   macro avg       0.52      0.52      0.50     82332\n","weighted avg       0.52      0.50      0.50     82332\n","\n","Confusion Matrix:\n"," [[23601 13399]\n"," [27408 17924]]\n"]}]},{"cell_type":"code","source":["from sklearn.metrics import roc_auc_score\n","\n","def evaluate_model(clf, X_test, y_test):\n","    import time\n","    start = time.perf_counter()\n","    y_pred = clf.predict(X_test)\n","    end = time.perf_counter()\n","    cls_latency = (end - start) / len(y_test) * 1000  # ms per sample\n","\n","    y_proba = clf.predict_proba(X_test)[:,1] if hasattr(clf, \"predict_proba\") else None\n","\n","    # Confusion matrix + FPR\n","    cm = confusion_matrix(y_test, y_pred, labels=[0,1])\n","    tn, fp, fn, tp = cm.ravel()\n","    fpr = fp / (fp + tn) if (fp + tn) > 0 else 0.0\n","\n","    results = {\n","        \"Accuracy\": accuracy_score(y_test, y_pred),\n","        \"Precision\": precision_score(y_test, y_pred),\n","        \"Recall\": recall_score(y_test, y_pred),\n","        \"F1\": f1_score(y_test, y_pred),\n","        \"ROC-AUC\": roc_auc_score(y_test, y_proba) if y_proba is not None else None,\n","        \"FPR\": fpr,\n","        \"ConfusionMatrix\": cm.tolist(),\n","        \"Latency_cls_ms\": cls_latency\n","    }\n","    return results"],"metadata":{"id":"G7FQ2qIcZtaH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ──────────────────────────────────────────────────────────────────────────────\n","# 6) Save to file (consistent with your NSL-KDD structure)\n","# ──────────────────────────────────────────────────────────────────────────────\n","import json\n","results = evaluate_model(clf, X_test, y_test)\n","with open(\"/content/drive/MyDrive/Results/UNSW/DecisionTree/Baseline_Decision_Tree_Results.txt\", \"w\") as f:\n","    json.dump(results, f, indent=2)"],"metadata":{"id":"DNVUEMfcideE"},"execution_count":null,"outputs":[]}]}